

# å®‰è£…LLaMA-Factoryä¾èµ–

é¦–å…ˆï¼Œå…‹éš†LLaMA-Factoryä»“åº“ï¼Œå¹¶å®‰è£…ä¾èµ–é¡¹ï¼š
```sh
git clone https://github.com/hiyouga/LLaMA-Factory
cd LLaMA-Factory
pip install -r requirements.txt
```

# æ•°æ®å¤„ç†

å°†æ•°æ®é›†å¤„ç†æˆ `Minicpm/finetune/llama_factory_example/llama_factory_data` æ–‡ä»¶å¤¹ä¸­çš„æ ¼å¼ï¼Œå¹¶æ”¾ç½®åˆ° `llama_factory/data` ç›®å½•ä¸‹ã€‚ç¤ºä¾‹åŒ…æ‹¬DPO, KTO, SFTä¸‰ç§å¾®è°ƒæ–¹å¼ã€‚

### 2.1 DPO æ•°æ®æ ¼å¼
```json
[
  {
    "conversations": [
      {
        "from": "human",
        "value": "Hi! I'd like to create a new language game simulating the first person perspective of a character named Angela."
      }
    ],
    "chosen": {
      "from": "gpt",
      "value": "That sounds like a fun and engaging idea! Here are some tips to help you create the game:\n1. Start with the character's name and background: "
    },
    "rejected": {
      "from": "gpt",
      "value": "Hello! ğŸ˜Š"
    }
  }
]
```

### 2.2 KTO æ•°æ®æ ¼å¼
æ¯ä¸ª `messages` ä»£è¡¨ä¸€æ¡æ•°æ®ï¼Œ`label` ä»£è¡¨è¯¥æ¡æ•°æ®çš„å›å¤æ˜¯å¦åˆç†ã€‚
```json
{
  "messages": [
    {
      "content": "The Federal Trade Commission is going after spyware, bits of computer code that install themselves on the computers of Internet users to track or disrupt their online activities.\nQ: Which is the best summary of this article?\nPick your answer from:\n(A). World\n(B). Sports\n(C). Business\n(D). Science/Tech\nI think the answer is",
      "role": "user"
    },
    {
      "content": "Ooh ooh ah ah! Science/Tech! Yay! *confetti* The Federal Trade Commission is talking about spyware, which is like a little computer bug that can watch what you do on your computer without you knowing. It's like a secret agent, but not a nice one! *gasp* The FTC wants to stop the spyware from doing its thing, so they're going after it! *cheer* Woohoo!",
      "role": "assistant"
    }
  ],
  "label": true // true or falseï¼Œ true is good response  ï¼Œfalse is bad response
}
```

### 2.3 SFT æ•°æ®æ ¼å¼
æ¯ä¸ªå­—å…¸ç»„æˆä¸€æ¡æ•°æ®ã€‚
```json
[
  {
    "instruction": "è¯†åˆ«å¹¶è§£é‡Šç»™å®šåˆ—è¡¨ä¸­çš„ä¸¤ä¸ªç§‘å­¦ç†è®ºï¼šç»†èƒç†è®ºå’Œæ—¥å¿ƒè¯´ã€‚",
    "input": "",
    "output": "ç»†èƒç†è®ºæ˜¯ç”Ÿç‰©ç§‘å­¦çš„ä¸€ä¸ªç†è®ºï¼Œå®ƒè®¤ä¸ºæ‰€æœ‰ç”Ÿå‘½ä½“éƒ½æ˜¯ç”±å¾®å°çš„åŸºæœ¬å•å…ƒâ€”â€”ç»†èƒæ‰€æ„æˆã€‚è¿™æ˜¯ç”Ÿç‰©å­¦çš„ä¸€ä¸ªåŸºç¡€ç†è®ºï¼Œè®¤ä¸ºç»†èƒæ˜¯æ‰€æœ‰ç”Ÿç‰©çš„åŸºæœ¬ç»“æ„å’ŒåŠŸèƒ½å•ä½ï¼Œæ‰€æœ‰çš„ç”Ÿç‰©éƒ½æ˜¯ç”±ä¸€ä¸ªæˆ–å¤šä¸ªç»†èƒç»„æˆï¼Œç»†èƒåªèƒ½é€šè¿‡ç»†èƒåˆ†è£‚äº§ç”Ÿæ–°çš„ç»†èƒã€‚è¿™ä¸€ç†è®ºç”±è–›å®šè°”ã€æ–½ç“¦å†…å’Œé›ªè±äº1839å¹´é¦–æ¬¡æå‡ºã€‚\n\næ—¥å¿ƒè¯´æ˜¯æŒ‡å¤ªé˜³æ˜¯å¤ªé˜³ç³»çš„ä¸­å¿ƒï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œè¡Œæ˜Ÿå›´ç»•å¤ªé˜³æ—‹è½¬çš„ç†è®ºã€‚è¿™ä¸ªç†è®ºæ‰“ç ´äº†ä¼ ç»Ÿçš„åœ°å¿ƒè¯´è§‚ç‚¹ï¼Œè®¤ä¸ºåœ°çƒå¹¶ä¸æ˜¯å®‡å®™çš„ä¸­å¿ƒã€‚æ—¥å¿ƒè¯´çš„æå‡ºè€…æ˜¯å°¼å¤æ‹‰Â·å“¥ç™½å°¼ï¼Œä»–åœ¨16ä¸–çºªåˆå‘è¡¨äº†ä»–çš„è‘—ä½œã€Šå¤©ä½“è¿è¡Œè®ºã€‹ï¼Œé˜è¿°äº†å¤ªé˜³ç³»è¡Œæ˜Ÿå›´ç»•å¤ªé˜³è¿è¡Œçš„æ¨¡å‹ï¼Œä¸ºå¤©æ–‡å­¦çš„å‘å±•åšå‡ºäº†å·¨å¤§è´¡çŒ®ã€‚"
  }
]
```

# å°†æ•°æ®ä¿¡æ¯æ·»åŠ åˆ° `dataset_info.json`

åœ¨ `llama_factory/data/dataset_info.json` ä¸­æ·»åŠ æ•°æ®é›†ä¿¡æ¯ï¼Œç¡®ä¿ `dataset_info.json` ä¸­èƒ½æ‰¾åˆ°ä½ çš„æ•°æ®é›†ã€‚
```json
{
  "identity": {
    "file_name": "identity.json"
  },
  "sft_zh_demo": {
    "file_name": "alpaca_zh_demo.json"
  },
  "kto_en_demo": {
    "file_name": "kto_en_demo.json",
    "formatting": "sharegpt",
    "columns": {
      "messages": "messages",
      "kto_tag": "label"
    },
    "tags": {
      "role_tag": "role",
      "content_tag": "content",
      "user_tag": "user",
      "assistant_tag": "assistant"
    }
  },
  "dpo_en_demo": {
    "file_name": "dpo_en_demo.json",
    "ranking": true,
    "formatting": "sharegpt",
    "columns": {
      "messages": "conversations",
      "chosen": "chosen",
      "rejected": "rejected"
    }
  }
}
```

# è®¾ç½®è®­ç»ƒè„šæœ¬

### 4.1 å¤åˆ¶ç¤ºä¾‹æ–‡ä»¶
å°† `MiniCPM/finetune/llama_factory_example` ä¸­çš„æ–‡ä»¶å¤åˆ¶åˆ° `LLaMA-Factory/examples/minicpm` ç›®å½•ä¸‹ã€‚
```sh
cd LLaMA-Factory/examples
mkdir minicpm
cp -r /your/path/MiniCPM/finetune/llama_factory_example/* /your/path/LLaMA-Factory/examples/minicpm
```

### 4.2 ä¿®æ”¹é…ç½®æ–‡ä»¶
æ ¹æ®éœ€è¦å¾®è°ƒçš„æ–¹å¼ï¼Œä»¥DPOä¸ºä¾‹ã€‚å¿…é¡»ä¿®æ”¹ `LLaMA-Factory/examples/minicpm/minicpm_dpo.yaml` ä¸­çš„é…ç½®å‚æ•°å¦‚ä¸‹ï¼š
```yaml
model_name_or_path: openbmb/MiniCPM-2B-sft-bf16 # æˆ–è€…ä½ æœ¬åœ°ä¿å­˜çš„åœ°å€
dataset: dpo_en_demo # è¿™é‡Œå†™dataset_info.jsonä¸­çš„é”®å
output_dir: your/finetune_minicpm/save/path # ä½ å¾®è°ƒåæ¨¡å‹çš„ä¿å­˜åœ°å€
bf16: true # å¦‚æœä½ çš„è®¾å¤‡æ”¯æŒbf16ï¼Œå¦åˆ™false
deepspeed: examples/deepspeed/ds_z2_config.json # å¦‚æœæ˜¾å­˜ä¸å¤Ÿå¯ä»¥æ”¹æˆds_z3_config.json
```

### 4.3 ä¿®æ”¹ `single_node.sh` æ–‡ä»¶
ä¿®æ”¹ `LLaMA-Factory/examples/minicpm/single_node.sh` æ–‡ä»¶ä¸­çš„ä»¥ä¸‹é…ç½®ï¼š
```sh
NPROC_PER_NODE=8
NNODES=1
RANK=0
MASTER_ADDR=127.0.0.1
MASTER_PORT=29500

# ä»¥ä¸‹ä¸¤è¡Œå¦‚æœæ˜¯A100ï¼ŒH100ç­‰ä»¥ä¸Šçš„é«˜ç«¯æ˜¾å¡å¯ä»¥åˆ é™¤
export NCCL_P2P_DISABLE=1
export NCCL_IB_DISABLE=1 

# ä»¥ä¸‹æ•°å­—è®¾ç½®ä¸ºä½ æœºå™¨ä¸­å‚ä¸è®­ç»ƒçš„æ˜¾å¡ï¼Œè¿™é‡Œæ˜¯0-7å·å¡éƒ½å‚ä¸è®­ç»ƒ
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 torchrun \
    --nproc_per_node $NPROC_PER_NODE \
    --nnodes $NNODES \
    --node_rank $RANK \
    --master_addr $MASTER_ADDR \
    --master_port $MASTER_PORT \ 

# ä»¥ä¸‹è¿™è¡Œéœ€è¦ä¿®æ”¹æˆé…ç½®æ–‡ä»¶åœ°å€
    src/train.py /your/path/LLaMA-Factory/examples/minicpm/minicpm_dpo.yaml
```

# å¼€å§‹è®­ç»ƒ

æœ€åï¼Œåœ¨ `LLaMA-Factory` ç›®å½•ä¸‹æ‰§è¡Œè®­ç»ƒè„šæœ¬ï¼š
```sh
cd LLaMA-Factory
bash /your/path/LLaMA-Factory/examples/minicpm/single_node.sh
```